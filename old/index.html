<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Acelerando a Otimização com IA e Supercomputação</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <h1>Briefing do Projeto:</h1>
        <h2>Acelerando a Otimização com Inteligência Artificial e Supercomputação</h2>
    </header>

    <main>
        <section id="sumario-executivo">
            <h3>Sumário Executivo</h3>
            <p>Este documento sintetiza um projeto de pesquisa internacional que visa revolucionar a resolução de problemas complexos de otimização combinatória, especificamente a Programação Linear Inteira Mista (MILP), por meio da integração de Inteligência Artificial (IA) e Computação de Alto Desempenho (HPC).</p>
            <p>O projeto aborda uma lacuna crítica na ciência da computação e na pesquisa operacional: embora os algoritmos de otimização como o MILP sejam fundamentais para setores como logística, energia e finanças, sua aplicação em problemas de grande escala é frequentemente limitada pela alta complexidade computacional. A pesquisa atual, embora promissora, carece de um consenso sobre como acelerar sistematicamente os solucionadores (solvers) de MILP.</p>
            <p><strong>Proposta Central:</strong> O projeto propõe o desenvolvimento de uma prova de conceito (PoC) de um protótipo de aprendizado profundo baseado na técnica "Aprender a Otimizar" (L2O - Learning to Optimize). Em vez de substituir os solvers tradicionais, o modelo de IA aprenderá a configurá-los de maneira otimizada e a fornecer soluções iniciais de alta qualidade (warm starts), acelerando drasticamente o tempo necessário para encontrar a solução ótima. O protótipo será desenvolvido e validado em um ambiente de supercomputação (HPC) on-premises.</p>
            <h4>Objetivos Estratégicos:</h4>
            <ul>
                <li><strong>Acelerar a Resolução de MILP:</strong> Demonstrar ganhos de velocidade (speedup) e eficiência em relação às configurações padrão dos solvers.</li>
                <li><strong>Prever o Tempo de Execução:</strong> Desenvolver um modelo capaz de estimar o tempo de execução de tarefas de otimização, fornecendo uma ferramenta valiosa para o planejamento operacional e simulação de políticas.</li>
                <li><strong>Desenvolver Ferramentas Abertas:</strong> Produzir e disponibilizar datasets, scripts e um protótipo de software de código aberto para garantir a reprodutibilidade e fomentar novas pesquisas.</li>
                <li><strong>Colaboração e Infraestrutura:</strong> A pesquisa é uma colaboração entre instituições brasileiras de ponta — Universidade de Brasília (UnB) e Universidade Federal do Rio Grande do Norte (UFRN) — e o prestigiado Instituto Andaluz Interuniversitário de Ciência de Dados e Inteligência Artificial (DaSCI) da Universidade de Jaén (UJA), na Espanha. O projeto terá acesso à infraestrutura de supercomputação de classe mundial do centro CEATIC da UJA, incluindo clusters equipados com GPUs NVIDIA A100 e V100, essenciais para o treinamento de modelos de IA avançados.</li>
            </ul>
            <p><strong>Impacto Esperado:</strong> O projeto visa gerar inovação incremental, elevando a tecnologia de um nível laboratorial (TRL4) para um protótipo validado em ambiente relevante (TRL6). Os resultados têm potencial para avançar o estado da arte na interseção da Pesquisa Operacional, IA e HPC, com futuras aplicações em desafios práticos de otimização em setores públicos e privados.</p>
        </section>

        <section id="contexto-e-justificativa">
            <h3>Contexto e Justificativa do Projeto</h3>
            <h4>A Relevância da Programação Linear Inteira Mista (MILP)</h4>
            <p>A Programação Linear Inteira Mista (MILP) é um poderoso framework matemático utilizado para modelar e resolver problemas complexos de tomada de decisão que envolvem variáveis contínuas e inteiras. Suas aplicações são vastas e críticas para a economia moderna, abrangendo áreas como:</p>
            <ul>
                <li>Logística e gestão da cadeia de suprimentos</li>
                <li>Planejamento energético e de produção</li>
                <li>Otimização de portfólios financeiros</li>
                <li>Telecomunicações e design de redes</li>
            </ul>
            <p>Nos últimos 20 anos, a capacidade de resolver problemas de MILP aumentou em até 1.000 vezes, impulsionada por avanços em hardware e algoritmos. No entanto, muitos problemas do mundo real, especialmente em campos emergentes como veículos autônomos e cibersegurança, continuam a exigir soluções em tempo real que desafiam os limites da tecnologia atual.</p>
            <h4>As Lacunas na Literatura Científica</h4>
            <p>Apesar dos avanços, a pesquisa para acelerar solvers de MILP ainda é emergente e fragmentada. O projeto identifica três lacunas principais que impedem um progresso mais rápido:</p>
            <ul>
                <li><strong>Dificuldade na Classificação de Problemas:</strong> A ausência de um método sistemático para classificar instâncias de problemas MILP dificulta a aplicação de estratégias de otimização específicas. Isso sugere a necessidade de substituir heurísticas manuais por abordagens de aprendizado adaptativo.</li>
                <li><strong>Potencial Não Comprovado da Técnica L2O:</strong> A abordagem "Aprender a Otimizar" (L2O) mostra grande potencial para melhorar o desempenho de solvers, mas ainda não foi definitivamente comprovada nem integrada de forma eficaz nas ferramentas existentes.</li>
                <li><strong>Otimização de Software em HPC Subexplorada:</strong> A literatura sobre como otimizar a resolução de MILP com algoritmos paralelos em ambientes de Computação de Alto Desempenho (HPC) é escassa e incipiente.</li>
            </ul>
        </section>

        <section id="objetivos-e-escopo">
            <h3>Objetivos e Escopo da Pesquisa</h3>
            <h4>Pergunta Central e Objetivo Geral</h4>
            <p>A pesquisa é guiada pela seguinte questão: “É possível melhorar o desempenho de solvers MILP com aprendizado profundo e computação de alto desempenho?”</p>
            <p>Para responder a essa pergunta, o projeto estabelece o seguinte objetivo geral:</p>
            <blockquote>
                Desenvolver e verificar, em 12 meses, uma prova de conceito (PoC) de um protótipo piloto de aprendizado profundo L2O que acelera e melhora o desempenho de solvers de otimização e fornece estimativas de intervalos de tempo de execução de jobs de MILP em HPC on-premises.
            </blockquote>
            <h4>Objetivos Específicos</h4>
            <p>O projeto está estruturado em cinco objetivos específicos e interligados:</p>
            <ol>
                <li><strong>O1 - Construir Cenários de Teste:</strong> Estabelecer um conjunto reprodutível de instâncias de problemas (extraídos de bibliotecas de benchmark como MIPLIB e MILPBench) e perfis de execução para testes rigorosos no ambiente HPC.</li>
                <li><strong>O2 - Padronizar a Coleta de Dados:</strong> Desenvolver scripts e um esquema padronizado para coletar dados ricos (logs, traços de execução, uso de recursos, parâmetros do solver), garantindo a qualidade e a reprodutibilidade dos experimentos.</li>
                <li><strong>O3 - Prototipar o Piloto L2O:</strong> Desenvolver o núcleo do projeto: um modelo de aprendizado profundo (rede neural) que, após treinamento, recomendará configurações de parâmetros otimizadas (presets) e gerará soluções iniciais (warm-starts) para acelerar o solver de MILP.</li>
                <li><strong>O4 - Obter Predição de Tempo de Execução:</strong> Utilizar os dados coletados durante o treinamento do modelo L2O para construir um sistema de previsão de tempo de execução, oferecendo estimativas pontuais e bandas de confiança (ex: HitRate@±25%) para apoio operacional.</li>
                <li><strong>O5 - Implementar Análise com IA Generativa:</strong> Desenvolver um agente de IA generativa para analisar e comunicar os resultados da pesquisa por meio de dashboards interativos, traduzindo dados técnicos complexos em sumários acessíveis para gestores e operadores.</li>
            </ol>
        </section>

        <section id="metodologia-e-tecnologia">
            <h3>Abordagem Metodológica e Tecnológica</h3>
            <h4>A Estratégia "Learning to Optimize" (L2O)</h4>
            <p>O núcleo metodológico do projeto é a técnica L2O, que representa uma mudança de paradigma em relação às abordagens tradicionais. Em vez de tentar substituir solvers complexos e bem estabelecidos, a L2O utiliza modelos de IA para guiá-los de forma inteligente. A abordagem se baseia em um tutorial recente de Chen, Liu e Yin (2024) e foca em duas frentes:</p>
            <ul>
                <li><strong>Pré-configuração do Solver:</strong> A rede neural será treinada para analisar as características de uma instância MILP e recomendar um conjunto de hiperparâmetros (um preset) que maximize a performance do solver para aquele tipo de problema específico.</li>
                <li><strong>Geração de Warm Starts:</strong> O modelo também aprenderá a prever uma solução inicial de alta qualidade. Fornecer essa "pista" ao solver pode podar drasticamente a árvore de busca do algoritmo branch-and-bound, levando a uma convergência muito mais rápida.</li>
            </ul>
            <p>Para a modelagem, o projeto explorará Redes Neurais de Grafos (GNN) e suas variantes convolucionais (GCNN), arquiteturas especialmente adequadas para representar a estrutura de problemas de otimização.</p>
            <h4>Plataforma de Testes e Coleta de Dados</h4>
            <p>Os experimentos serão conduzidos de forma rigorosa e sistemática:</p>
            <ul>
                <li><strong>Solvers:</strong> Serão utilizados solvers de ponta, incluindo o Gurobi (comercial, com licença acadêmica) e o SCIP (código aberto), permitindo a comparação de desempenho e a validação em diferentes plataformas.</li>
                <li><strong>Ambiente HPC:</strong> A coleta de dados será realizada em um ambiente HPC on-premises, possivelmente gerenciado pelo Slurm, refletindo um cenário de uso real em centros de pesquisa e grandes organizações.</li>
                <li><strong>Instrumentação:</strong> Um runner padronizado será desenvolvido para automatizar a execução das instâncias, registrando métricas essenciais como tempos de espera e execução, uso de recursos (CPU, memória), eventos do solver e configurações aplicadas.</li>
            </ul>
            <h4>Métricas de Sucesso</h4>
            <p>O desempenho do protótipo L2O será avaliado em relação a linhas de base (configurações padrão do solver) usando um conjunto de métricas claras e objetivas:</p>
            <table>
                <thead>
                    <tr>
                        <th>Categoria</th>
                        <th>Métrica</th>
                        <th>Descrição</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Desempenho (Primárias)</td>
                        <td>Speedup (S)</td>
                        <td>Mede quantas vezes o método L2O é mais rápido que a linha de base.</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>Eficiência (E)</td>
                        <td>Avalia o ganho de velocidade em relação aos recursos computacionais consumidos.</td>
                    </tr>
                    <tr>
                        <td>Predição</td>
                        <td>MdAPE</td>
                        <td>Erro Percentual Absoluto Mediano; mede o erro "típico" da previsão de tempo de execução.</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>HitRate@±α%</td>
                        <td>Fração de previsões que ficaram dentro de uma margem de erro aceitável (ex: ±25%).</td>
                    </tr>
                    <tr>
                        <td>Operacionais (Desejáveis)</td>
                        <td>Tempo de Espera</td>
                        <td>Métricas de fila que indicam o impacto no ambiente de produção, como tempo médio de espera e throughput de jobs.</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="colaboracao-e-infraestrutura">
            <h3>Colaboração Internacional e Infraestrutura</h3>
            <h4>A Parceria Estratégica com o Instituto DaSCI (Espanha)</h4>
            <p>A colaboração com o Instituto Andaluz Interuniversitário DaSCI da Universidade de Jaén é um pilar do projeto. O DaSCI é um centro de excelência em IA e Ciência de Dados, sendo a UJA classificada como a terceira melhor universidade da Espanha em Inteligência Artificial pelo ranking U.S. News & World Report (2025). A parceria oferece uma sinergia fundamental:</p>
            <ul>
                <li>A equipe brasileira contribui com expertise em Pesquisa Operacional, IA aplicada e HPC.</li>
                <li>A equipe espanhola, liderada pelo Prof. Dr. Pedro Gonzalez Garcia, complementa com profundo conhecimento em mineração de dados em larga escala, algoritmos evolucionários e processamento em ambientes HPC.</li>
            </ul>
            <h4>Infraestrutura de Supercomputação (CEATIC)</h4>
            <p>O projeto terá acesso à infraestrutura avançada do Centro de Estudos Avançados em Tecnologias da Informação e da Comunicação (CEATIC) da UJA. Essa infraestrutura é essencial para a viabilidade da pesquisa e inclui:</p>
            <ul>
                <li><strong>Cluster ADA (GPU):</strong> Projetado para IA e HPC, equipado com nós contendo GPUs de última geração, como NVIDIA Tesla A100 (Ampere), Tesla V100 (Volta) e GeForce RTX 2080 Ti. Esses recursos são cruciais para treinar os modelos de aprendizado profundo de forma eficiente.</li>
                <li><strong>Cluster TURING (HPC e Big Data):</strong> Composto por 32 nós de computação e Big Data, ideal para executar simulações paralelas intensivas em CPU e pré-processamento de grandes volumes de dados.</li>
                <li><strong>Serviços de Virtualização e Nuvem:</strong> Uma infraestrutura flexível baseada em Proxmox VE, permitindo a criação de ambientes de teste isolados e o compartilhamento seguro de datasets e resultados.</li>
            </ul>
        </section>
        
        <section id="relevancia-e-impactos">
            <h3>Relevância e Impactos Esperados</h3>
            <h4>Contribuições Científicas e Tecnológicas</h4>
            <p>O projeto foi desenhado para gerar produtos concretos e de alto valor para a comunidade científica e tecnológica:</p>
            <ul>
                <li><strong>Dataset Aberto e Reprodutível:</strong> Um conjunto de dados com instâncias e perfis de execução, documentado e publicado.</li>
                <li><strong>Repositório de Scripts:</strong> Código aberto com os scripts de configuração, submissão e coleta, além dos esquemas de logs, promovendo a ciência aberta.</li>
                <li><strong>Software (Piloto L2O):</strong> O protótipo L2O terá seu código-fonte disponibilizado e sua propriedade intelectual registrada, com potencial para integração futura em solvers de código aberto.</li>
                <li><strong>Publicações Científicas:</strong> Geração de artigos para periódicos e congressos de alto impacto nas áreas de PO, IA e HPC.</li>
                <li><strong>Dashboard de Resultados:</strong> Uma ferramenta de visualização que demonstra os ganhos de eficiência de forma clara e acessível.</li>
            </ul>
            <h4>Inovação e Potencial de Aplicação</h4>
            <p>A principal inovação do projeto reside na integração de três campos distintos (PO, IA, HPC) para resolver um problema prático e desafiador. Ao final dos 12 meses, espera-se avançar o conjunto de tecnologias do nível de maturidade tecnológica TRL4 (validação em laboratório) para TRL6 (protótipo demonstrado em ambiente relevante). Essa prova de conceito abrirá caminho para futuros desenvolvimentos e aplicações em setores que dependem criticamente de otimização, como energia, logística, transporte e finanças.</p>
        </section>

        <section id="plano-divulgacao-cientifica">
            <h3>Plano de Divulgação Científica</h3>
            <p>O projeto inclui um plano de divulgação científica (PDC) abrangente e multifacetado, com o objetivo de tornar o conhecimento gerado acessível a um público amplo e não especializado. As principais ações incluem:</p>
            <ul>
                <li><strong>Comunicação Digital:</strong> Criação de um microsite do projeto (em português, espanhol e inglês), gestão de canais em redes sociais (LinkedIn, YouTube), e produção de podcasts e webinários.</li>
                <li><strong>Materiais Acessíveis:</strong> Elaboração de tutoriais em vídeo, notebooks interativos e um e-book final em linguagem acessível, explicando os conceitos e resultados da pesquisa.</li>
                <li><strong>Engajamento Acadêmico e Público:</strong> Submissão de artigos científicos, registro de software, e participação em eventos, feiras e mostras de inovação.</li>
            </ul>
        </section>

        <section id="equipe-e-governanca">
            <h3>Equipe e Governança</h3>
            <p>O sucesso do projeto será garantido por uma equipe multidisciplinar e uma governança clara.</p>
            <table>
                <thead>
                    <tr>
                        <th>Função</th>
                        <th>Responsável</th>
                        <th>Instituição</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Coordenador do Projeto</td>
                        <td>Prof. Dr. Victor Rafael Rezende Celestino</td>
                        <td>Universidade de Brasília (UnB)</td>
                    </tr>
                    <tr>
                        <td>Supervisor Acadêmico (Internacional)</td>
                        <td>Prof. Dr. Pedro Gonzalez Garcia</td>
                        <td>DaSCI / Universidade de Jaén (UJA)</td>
                    </tr>
                    <tr>
                        <td>Colaboradores (Brasil)</td>
                        <td>Pesquisadores do LAMFO e LAICO</td>
                        <td>Universidade de Brasília (UnB)</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>Pesquisadores do LAPPS</td>
                        <td>Universidade Federal do Rio Grande do Norte (UFRN)</td>
                    </tr>
                    <tr>
                        <td>Colaboradores (Espanha)</td>
                        <td>Pesquisadores do DaSCI</td>
                        <td>Universidade de Jaén (UJA)</td>
                    </tr>
                </tbody>
            </table>
            <p>A governança incluirá reuniões quinzenais de acompanhamento e a entrega de relatórios trimestrais para garantir o alinhamento e o cumprimento das metas estabelecidas.</p>
        </section>
    </main>

    <footer>
        <p>Este material foi gerado a partir do briefing do projeto "Acelerando a Otimização com IA e Supercomputação".</p>
    </footer>

</body>
</html>